name: RoBERTa-base vs NB-BERT evaluation (3 runs, 10 epochs)
project: roberta-base-vs-nb-bert-eval
program: notram_eval.py
entity: nbailab
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args}
method: grid
metric:
  name: eval/f1_macro
  goal: maximize
parameters:
  dataset_name:
    value: norne:bokmaal
  task_name:
    values:
    - ner
    - pos
  model_name:
    values:
    - NbAiLab/nb-bert-base
    - NbAiLab/nb-roberta-base-bokmaal
    - pere/norwegian-roberta-base-highlr-512
    - NbAiLab/nb-roberta-base-social
  from_flax:
    value: true
  force_download:
    value: true
  num_train_epochs:
    value: 10
  warmup_steps:
    value: 0.06
  weight_decay:
    value: 0.0
  learning_rate:
    values:
    - 1e-5
    - 2e-5
    - 3e-5
  train_batch_size:
    values:
    - 32
    - 16
  run:
    values: [1, 2, 3]
  cache_dir:
    value: ./cache
  output_dir:
    value: ./output
